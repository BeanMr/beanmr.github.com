{"meta":{"title":"逗哥的代码作坊","subtitle":"互联网是一门实践性科学","description":null,"author":"FengDD","url":"http://blog.beanmr.com","root":"/"},"pages":[{"title":"categories","date":"2019-03-15T09:57:33.000Z","updated":"2019-03-20T03:50:14.100Z","comments":false,"path":"categories/index.html","permalink":"http://blog.beanmr.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-03-15T09:56:39.000Z","updated":"2019-03-20T03:50:14.099Z","comments":false,"path":"tags/index.html","permalink":"http://blog.beanmr.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"图解Innodb锁子系统","slug":"2016-8-2-graphic-innodb-lock","date":"2019-03-20T03:11:10.068Z","updated":"2019-03-20T03:50:14.015Z","comments":true,"path":"2016-8-2-graphic-innodb-lock/","link":"","permalink":"http://blog.beanmr.com/2016-8-2-graphic-innodb-lock/","excerpt":"","text":"InnoDB锁子系统设计目标逻辑锁设计及行级锁问题Innodb存储模型数据库文件123456789101112131415161718show variables like 'innodb_file_per_table';+-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| innodb_file_per_table | ON |+-----------------------+-------+1 row in set (0.00 sec)create database `graphic_innodb`;CREATE TABLE `graphic_innodb`.`db_file_store` ( `clu_key` INT NOT NULL AUTO_INCREMENT, `idx_key` VARCHAR(45) NULL, `data_col` VARCHAR(3800) NULL, PRIMARY KEY (`clu_key`), INDEX `se_idx` USING BTREE (`idx_key` ASC))ENGINE = InnoDBDEFAULT CHARACTER SET = latin1; 14.11.2 Role of the .frm File for InnoDB Tables MySQL stores its data dictionary information for tables in .frm files in database directories. Unlike other MySQL storage engines, InnoDB also encodes information about the table in its own internal data dictionary inside the tablespace. When MySQL drops a table or a database, it deletes one or more .frm files as well as the corresponding entries inside the InnoDB data dictionary. You cannot move InnoDB tables between databases simply by moving the .frm files. 1234567891011121314% python py_innodb_page_info.py -v /usr/local/mysql/data/graphic_innodb/db_file_store.ibdpage offset 00000000, page type &lt;File Space Header&gt;page offset 00000001, page type &lt;Insert Buffer Bitmap&gt;page offset 00000002, page type &lt;File Segment inode&gt;page offset 00000003, page type &lt;B-tree Node&gt;, page level &lt;0000&gt;page offset 00000004, page type &lt;B-tree Node&gt;, page level &lt;0000&gt;page offset 00000000, page type &lt;Freshly Allocated Page&gt;page offset 00000000, page type &lt;Freshly Allocated Page&gt;Total number of page: 7:Freshly Allocated Page: 2Insert Buffer Bitmap: 1File Space Header: 1B-tree Node: 2File Segment inode: 1 InnoDB锁子系统关键对象InnoDB行级锁对象","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.beanmr.com/categories/MySQL/"}],"tags":[{"name":"InnoDB","slug":"InnoDB","permalink":"http://blog.beanmr.com/tags/InnoDB/"},{"name":"Lock","slug":"Lock","permalink":"http://blog.beanmr.com/tags/Lock/"}]},{"title":"起底InnoDB锁子系统-事务锁细节解析","slug":"2016-7-21-innodb-lock-detail","date":"2019-03-20T03:11:10.067Z","updated":"2019-03-20T03:50:14.098Z","comments":true,"path":"2016-7-21-innodb-lock-detail/","link":"","permalink":"http://blog.beanmr.com/2016-7-21-innodb-lock-detail/","excerpt":"","text":"当前大多数材料介绍InnoDB锁机制基本都是从锁分析的层面，对于InnoDB加锁的细节并没有过多的披露。比如材料会介绍某个场景InnoDB会对哪些记录加锁、加何种锁；但是没有介绍是如何InnoDB完成的加锁、锁结构是如何的。本文的内容将深入介绍InnoDB的事务锁子系统，将解读InnoDB行级锁为什么性能损耗不是很大、锁实例维护的对象如何组织、加锁过程是如何完成的、锁对象是如何维护的。 InnoDB的事务锁子系统内部锁相关数据结构表级锁TABLE LOCK_ISTABLE LOCK_IX加锁过程分析行级锁行级锁组织结构隐式行级锁处理显式行级锁处理显示S锁显式X锁GAP锁处理锁释放死锁检测","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.beanmr.com/categories/MySQL/"}],"tags":[{"name":"InnoDB","slug":"InnoDB","permalink":"http://blog.beanmr.com/tags/InnoDB/"},{"name":"Lock","slug":"Lock","permalink":"http://blog.beanmr.com/tags/Lock/"}]},{"title":"InnoDB死锁分析-锁基础理论","slug":"2016-7-13-innodb-lock","date":"2019-03-20T03:11:10.060Z","updated":"2019-03-20T03:50:14.097Z","comments":true,"path":"2016-7-13-innodb-lock/","link":"","permalink":"http://blog.beanmr.com/2016-7-13-innodb-lock/","excerpt":"","text":"死锁是由加锁引起的，要解决死锁首先要明白为什么加锁、加什么样的锁。本篇主要讨论锁相关的一些基础理论以及InnoDB的MVCC特性。 锁的基础理论为什么加锁数据库与其它涉及并发的程序一样，都要处理并发的两个关键点互斥和协作；锁就是为了保证互斥特性，让多用户请求可以一致性的读取和修改数据。如果不通过加锁来控制访问的一致性则会造成脏读、幻读、不可重复读等问题。 锁模式锁就是为了保证某个资源被按照合理的顺序被访问。如果使用一个简单的互斥锁来保护资源，那么当多个读取者访问资源并且期间没有其它的写入者访问，那么每个读取者依旧要依次获取锁资源，但是最终每个读取者获取的还是同一个结果。这样就限制了系统的并发性能，毕竟我们使用锁的原因是希望通过并发来提高系统性能同时依靠锁来解决并发引起的问题。 如果我们为读写者提供不同的锁，对于被读取者的锁保护的资源允许其它的读取者再加上一把锁并且限制其它的写入者加锁；这样我们就能保证了上述情况下所有的读取者最终获取的结果与之前相同。这样即可以保证系统的安全又可以保证并发的性能，这就是锁模式的一个维度的表现。通常情况下我们将这种锁根据其特性不同分别命名为共享锁 S和排它锁 X。 如上所述，不同的锁之间有的能“叠加”有的则是互斥的，这就是锁的兼容性。 S X S 兼容 不兼容 X 不兼容 不兼容 众所周知加锁操作需要有构建锁对象，维护锁对象关系等一系列操作，这都会消耗系统性能。假如一个操作者访问某个资源对它进行了加锁操作，但是在它整个操作过程都没有其它人来访问这个资源；如此这个加锁操作的资源消耗就白白浪费了也等于限制了系统的并发性能。那么如果我们在加锁的时候不真正的执行加锁动作，而是在那里贴一个小纸条标示有人来过并且要加锁。这样如果没有其它人来访问此资源则依旧安全并且避免了加锁消耗；如果有人来访问资源其看到这个意向小纸条则为先进去那个人完成加锁操作并且将自己添加到这个锁等待之中，如此依旧保证了系统的安全。这就是锁模式的另外一个维度意向锁。 综上所述,我们将锁按照不同的模式分为S X两种，同时这两种锁又可以依靠意向标识来表示则为IS IX锁总共4种不同的锁，这就是Multiple granularity locking。 InnoDB存储引擎支持意向锁设计比较简练；众所周知InnoDB支持行级锁，其意向锁用于表级锁，设计目的主要是为了揭示行级锁的类型。InnoDB支持IS和IX锁两种意向锁： IX表示事务想要获得一张表中某几行的排他锁 IS表示事务想要获得一张表中某几行的共享锁 IS IX S X IS 兼容 兼容 兼容 不兼容 IX 兼容 兼容 不兼容 不兼容 S 兼容 不兼容 兼容 不兼容 X 不兼容 不兼容 不兼容 不兼容 锁粒度比如系统的资源是一家里面有很多房子的宾馆，一种加锁方式是当有人入住以后将整个宾馆锁起来，另外一种方式就是锁住入住的房子，这就是锁粒度的划分。 InnoDB支持行级锁，一般认为行级锁会消耗更多资源，但是实际上InnoDB的实现不需要锁升级，其依赖bitmap实现所以一个锁和多个锁的开销是相同的。 lock与latch最后再讨论一下一个容易混淆的概念lock与latch。 latch一般称之为闩锁是一种轻量级的锁，latch又可以分为mutex(互斥量)和rwlock(读写锁)。其主要的目的是保证并发线程操作临界资源的正确性。这种锁没有死锁检测机制，所以这里发生了死锁不能被检测出来并恢复处理。lock的对象是事务，用于锁定的是数据库中的对象，比如表、页、行。根据二阶段加锁协议此类lock对象仅仅在commit和rollback后才进行释放。这里是有死锁检测机制的，InnoDB采用Wait-For-Graph算法来实现死锁检测的。 InnoDB存储引擎中的Latch可以通过SHOW ENGINE INNODB MUTEX来查看1234567891011mysql&gt; SHOW ENGINE INNODB MUTEX;+--------+-------------------+-------------+| Type | Name | Status |+--------+-------------------+-------------+| InnoDB | dict0dict.cc:1057 | os_waits=2 || InnoDB | log0log.cc:844 | os_waits=1 || InnoDB | fil0fil.cc:1690 | os_waits=1 || InnoDB | dict0dict.cc:1066 | os_waits=3 || InnoDB | log0log.cc:907 | os_waits=11 |+--------+-------------------+-------------+5 rows in set (4.14 sec)在Debug模式下SHOW ENGINE INNODB MUTEX能显示更多的信息 各个字段的描述如下 相对于latch来看，lock信息就显得直观了。可以通过SHOW ENGINE INNODB STATUS 及information_schema架构下的INNODB_TRX、INNODB_LOCKS、INNODB_LOCK_WAITS来观察锁的信息 。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.beanmr.com/categories/MySQL/"}],"tags":[{"name":"InnoDB","slug":"InnoDB","permalink":"http://blog.beanmr.com/tags/InnoDB/"},{"name":"Lock","slug":"Lock","permalink":"http://blog.beanmr.com/tags/Lock/"}]},{"title":"InnoDB死锁分析、解决方法论梳理","slug":"2016-7-13-innodb-deadlock-overview","date":"2019-03-20T03:11:10.057Z","updated":"2019-03-20T03:50:14.015Z","comments":true,"path":"2016-7-13-innodb-deadlock-overview/","link":"","permalink":"http://blog.beanmr.com/2016-7-13-innodb-deadlock-overview/","excerpt":"","text":"在工作中遇到了两个死锁报警，梳理一下关于Innodb死锁相关的知识。主要的内容并不是相关的知识点而是相关知识体系的梳理。最终提供的分析及解决方法论、解决方案也是通用性的提示；本着具体情况具体分析的原则所以这些提示的应用需要相应的知识点进行支撑。 加锁分析法解决死锁首先要了解死锁发生的原因，加锁分析法也就是死锁解决的最基础能力。 当然进行分析首先需要尽可能的收集各种已知的信息，所以理解Innodb Status、information_schema的innodb表、innodb_status_output日志等内容也就成了必备能力。 在进行加锁分析的过程中，可能有些细节并不能很好的根据已知的条目进行解释，这时候最好的方法就是看看代码运行过程中实际加了哪些锁。通过代码调试可以更好的了解加锁的细节、印证加锁的猜测，所以代码调试功能可以说是死锁分析法的高级辅助手段。 当然要想了解每个细节，最终的方法还是阅读源码，但是对于一个非DBA的程序开发人员来说可能没有必要。大多数情况根据已知的InnoDB的加锁原则就能找到问题，也就是根据图片右上、左上两部分的知识点即可以完成。 解决方案提示解决方案主要划分为日常检测、SQL优化、代码级别鲁棒性处理及数据库调整。这些内容都是通用性提示，具体情况具体分析才能找到最优的解决方案。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.beanmr.com/categories/MySQL/"}],"tags":[{"name":"InnoDB","slug":"InnoDB","permalink":"http://blog.beanmr.com/tags/InnoDB/"},{"name":"Deadlock","slug":"Deadlock","permalink":"http://blog.beanmr.com/tags/Deadlock/"}]},{"title":"SublimeText自定义代码片段","slug":"2016-6-21-sublime-text-snippet","date":"2019-03-20T03:11:10.052Z","updated":"2019-03-20T03:50:14.031Z","comments":true,"path":"2016-6-21-sublime-text-snippet/","link":"","permalink":"http://blog.beanmr.com/2016-6-21-sublime-text-snippet/","excerpt":"","text":"写文章或者写代码时常常要输入一些模板型的代码片段。模块代码片段有的已经在IDE中内嵌，但是像下面这种自定义的规则就需要自己定制了。比如下面这个语句就是我自定义的在文章中插入图片的片段；我没有使用固定的路径；我与自己约定，文章的图片存放在/{media_repos}/文章文件名/图片文件位置上。 {% asset_img /1.png %} 在SublimeText中自定代码片段的方法如下： 找到Package文件夹 进入Package&gt;User&gt;新建文件 文件名为 tag_name.sublime-snippet 文件内容如下，保存并重启Sublime即可123456789&lt;snippet&gt; &lt;content&gt;&lt;![CDATA[&#123;% image &#123;&#123; '$&#123;2:img&#125;' 'page.path|remove:_posts/|remove:.md|prepend:site.media_repos|append:/$&#123;1:1&#125;.png&#125;&#125;' %&#125;]]&gt;&lt;/content&gt; &lt;!-- 可选: 键入以下内容按Tab触发片段替换 --&gt; &lt;tabTrigger&gt;postimg&lt;/tabTrigger&gt; &lt;!-- 可选: 在哪类文件中生效 --&gt; &lt;!-- &lt;scope&gt;source.md&lt;/scope&gt; --&gt;&lt;/snippet&gt; 自定义代码片段支持变量替换其中${2:img}代表变量替换；其中2代表片段替换后光标定位顺序，img代表此变量默认值。片段替换以后按Tab即可以进行光标依次定位。 {%raw%}标签 使liquid不渲染其内部内容{%endraw%}","categories":[{"name":"Tools","slug":"Tools","permalink":"http://blog.beanmr.com/categories/Tools/"}],"tags":[{"name":"SublimeText","slug":"SublimeText","permalink":"http://blog.beanmr.com/tags/SublimeText/"}]},{"title":"[回顾MySQL]体系结构-动态结构","slug":"2016-6-18-mysql-dynamic-arch","date":"2019-03-20T03:11:10.046Z","updated":"2019-03-20T03:50:14.037Z","comments":true,"path":"2016-6-18-mysql-dynamic-arch/","link":"","permalink":"http://blog.beanmr.com/2016-6-18-mysql-dynamic-arch/","excerpt":"","text":"上一个章节从静态组成角度分析了MySQL服务器的组成部分；本章节从一个SQL执行的过程分析MySQL各个组件之间的协作和作用。 简单的说MySQL服务器正常启动以后，开始监听客户端的请求。客户端发送请求与服务器建立连接，之后客户端发送请求、接收返回。 服务器启动阶段系统初始化模块会负责读取配置文件、初始化系统、申请内存创建系统需要的各种Cache、Buffer，这部分属于管理服务及工具组件，系统正常启动以后网络交互模块将监听指定的服务端口等待客户端的连接。 服务器与客户端建立连接网络交互组件负责着监听客户端请求、交互协议处理；MySQL服务器与客户端之间采用MySQL Client/Server Protocol进行交互，从5.7.12开始支持了新的交互协议X Procotol这里有一篇博文对其进行了介绍。 服务器与客户端之间建立连接的过程就是由这个协议规定的，如下图所示。在建立连接以后在ConnectionPool中就有一个独立的线程与客户端保持联系，并负责初期请求的转发、结果集的包装与发送。 query_slow_log的时间包含网络发送的时间 结果集的大小、发送方式都会影响此数值 MySQL Client/Server Protocol协议的设计上支持了以下特性： SSL加密传输 内容压缩传输 用于交互功能(capabilities)和认证数据的连接阶段 用于Prepared Statments和存储过程的command-phase 以下组件都是MySQL Client/Server Protocol的实现，当前它们根据目的不同可能实现的是协议的不同子集： Connectors (比如JDBC、ODBC等) MySQL Proxy(比如MySQL Proxy/360 Atlas等代理服务机制) 主从复制 Replication Protocol MySQL Client/Server Protocol有以下协议子集： Text Protocol Prepared Statements Stored Procedures Replication Protocol Row-Based Replication Semi-Synchronous Replication Prepared Statements ProtocolPrepared Statements Protocol就是处理我们开发中最常用的PreparedStatement的协议。它的核心理念其实就是采用预编译或者参数化的手段来提升需要重复执行的语句总效率，当然还有另外一个选择PreparedStatement的核心理由那就是参数化的模板可以有效的防范SQL注入攻击。 其一般的工作流程成如下： Prepare：应用程序创建Statement模板发送到DBMS，使用占位符来代替具体的数值。 DBMS对模板进行解析、编译、进行查询优化、执行计划制定等操作，并将结果暂存到服务器中。 在Client调用Statement的时候，DBMS执行之前的计划并返回结果。 另外因为语句进行过预编译所以服务器可以提前告知结果集的格式；那么采用Binary方式返回数据可以进一步提高信息熵，减少网络负载提高系统速度。 但是并不是所有的SQL语句都可以Prepared，这里有个表格可以浏览一下。 Text Protocol相对而言Text Protocol更利于我们学习和分析，从它的定义中我们可以找到如下一系列的命令，这就是在后续CS交互过程中服务器要处理的命令。 COM_SLEEP COM_QUIT COM_INIT_DB COM_QUERY COM_FIELD_LIST COM_CREATE_DB COM_DROP_DB COM_REFRESH COM_SHUTDOWN COM_STATISTICS COM_PROCESS_INFO COM_CONNECT COM_PROCESS_KILL COM_DEBUG COM_PING COM_TIME COM_DELAYED_INSERT COM_CHANGE_USER COM_RESET_CONNECTION COM_DAEMON 请求分发客户端与服务器建立连接以后，即可以向服务器发送请求。不同的请求类型将会被dispatch_command分发到不同的处理模块进行处理。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** Perform one connection-level (COM_XXXX) command. @param command type of command to perform @param thd connection handle @param packet data for the command, packet is always null-terminated @param packet_length length of packet + 1 (to show that data is null-terminated) except for COM_SLEEP, where it can be zero. @todo set thd-&gt;lex-&gt;sql_command to SQLCOM_END here. @todo The following has to be changed to an 8 byte integer @retval 0 ok @retval 1 request of thread shutdown, i. e. if command is COM_QUIT/COM_SHUTDOWN*/bool dispatch_command(enum enum_server_command command, THD *thd, char* packet, uint packet_length) ...... case COM_STMT_EXECUTE: &#123; mysqld_stmt_execute(thd, packet, packet_length); break; &#125; case COM_STMT_FETCH: &#123; mysqld_stmt_fetch(thd, packet, packet_length); break; &#125; case COM_STMT_SEND_LONG_DATA: &#123; mysql_stmt_get_longdata(thd, packet, packet_length); break; &#125; case COM_STMT_PREPARE: &#123; mysqld_stmt_prepare(thd, packet, packet_length); break; &#125; case COM_STMT_CLOSE: &#123; mysqld_stmt_close(thd, packet); break; &#125; 请求被分发到对应的处理模块后，返回的结果集合再由连接线程构建成相应的协议返回结果，基础的流程如下： 命令的解析与执行在Connection-Level的command_dispath之后，各个命令会到达相应的模块。这些模块会对请求进行解析、之后开始调用各个底层接口方法完成命令。 另外各个模块收到请求后，首先会通过访问控制模块检查连接用户是否有访问目标表以及目标字段的权限。如果用户拥有相应的权限，那么就会向表管理的模块请求相应的表及对应的锁。 表管理模块首先会检查表是否打开、是否存在于Table Cache之中；如果表没有被打开则打开相应的表然后继续后续的所操作。当表打开后表管理模块就可以根据表的meta信息，判断表的存储引擎等信息；根据表的存储引擎，命令执行模块就可以将需要的请求提交给存储引擎对应的实例接口进行处理。 如同上文提到的MySQL的存储引擎插件是基于表层面的，所以对于表变更管理模块来说，可见的仅是存储引擎接口模块所提供的一系列“标准”接口。底层存储引擎实现模块的具体实现，对于表变更管理模块来说是透明的。他只需要调用对应的接口，并指明表类型，接口模块会根据表类型调用正确的存储引擎来进行相应的处理。 在处理过程中产生的数据库的变化及数据库中数据的变化将会被相应的信息收集服务感知，进而动态的为数据库的运行优化及查询执行计划决策提供数据支持。 另外为了提升性能数据库还会在这个过程中有大量的优化，比如针对SELECT语句解析器会首先查询Query Cache之中是否已经存在可靠的预编译结果、解析结果、执行结果，如果命中缓存则可以简化相应的步骤。 其它辅助模块相关模块使数据库中的数据发生了变化，而且MySQL 打开了binlog功能，则对应的处理模块还会调用日志处理模块将相应的变更语句以更新事件的形式记录到相关参数指定的二进制日志文件中。在上面各个模块的处理过程中，各自的核心运算处理功能部分都会高度依赖整个MySQL的核心API 模块，比如内存管理，文件I/O，数字和字符串处理等等。 最后分享网上一个小伙伴的图片 本人是一名应用开发工程师并非DBA 所述内容大多来自对网上小伙伴的分享学习理解 以及MySQL手册 如果纰漏或者理解有误之处 万望各位小伙伴不吝赐教 参考资料： https://dev.mysql.com/doc/internals/en/overview.html https://dev.mysql.com/doc/refman/5.7/en/ http://tigerlchen.iteye.com/blog/1770518 http://www.orczhou.com/index.php/tag/mysql/","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.beanmr.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.beanmr.com/tags/MySQL/"},{"name":"Architecture","slug":"Architecture","permalink":"http://blog.beanmr.com/tags/Architecture/"}]},{"title":"[回顾MySQL]体系结构-静态组成","slug":"2016-6-17-mysql-static-arch","date":"2019-03-20T03:11:10.042Z","updated":"2019-03-20T03:50:14.009Z","comments":true,"path":"2016-6-17-mysql-static-arch/","link":"","permalink":"http://blog.beanmr.com/2016-6-17-mysql-static-arch/","excerpt":"","text":"本章节主要回顾MySQL数据库的系统结构，梳理MySQL服务器各个组成部分及其功能。 数据库与数据库实例在介绍MySQL的体系结构之前，首先区分一个容易混淆的概念–数据库与数据库实例。大多数情况我们并不强调两者的差别，但作为MySQL与Oracle/SQL Server在结构上的重要区别还是有必要了解的。 从概念上说数据库是一组按照某种数据模型组织起来的、保存于二级存储中的文件集合；而数据库实例指的是数据库管理程序。对于Oracle来说一个数据库运行于一个数据库实例之中，而MySQL支持单实例多数据库，也就是说我们可以启动一个MySQL程序而在上面创建并运行多个数据库。后续我们将不再强调区分数据库与数据库实例。 MySQL的静态体系结构 上图来自MySQL官方手册，可以看到MySQL数据库主要由一下几部分组件构成。 连接池组件 主要负责监听发送到MySQL连接请求，对连接进行认证鉴权，然后将请求转发到连接线程、连接线程将负责Server与Client的通信，连接池组件负责管理这些连接线程及线程池，进行线程的创建、销毁、复用以及线程Cache、内存的管理。 管理服务及工具组件 负责着服务器的管理、配置、元数据、备份、恢复、安全功能，复制、集群功能也在这部分实现。 SQL接口 负责处理SQL功能，包括DML、DDL、存储过程、视图、触发器等。SQL语句的含义被转换为对数据库的操作，其中查询语句包含了我们绝多数对数据库的需求，这些查询将被送到查询解析器进行处理，最终生成执行计划，执行并返回我们所需的数据。 查询分析器组件 查询分析器解析SQL查询语句生成MySQL内部的对象，这个过程就是查询翻译的过程；同时在这个过程还有对象权限的校验工作。这部分基本就是一个编译器做的工作，一般基础流程为词法分析、语法分析、最终生成抽象语法树(AST)。词法分析器和语法分析器可以HardCode，但为了简洁可靠人们更多的使用一些已有的组件技术，其中Flex和Bison的组合是最著名的。Flex负责进行词法解析、Bison进行语法分析。但是MySQL为了保证灵活和性能，没有采用Flex而是自己实现了一个分析器；然后用Bison进行语法分析生成MySQL内部的Item对象构成AST。有一本关于flex/bison的书实例演示了一个SQL词法、语法解析器。作为一个程序人员对这一块理解并不深入，因为它就是负责一个翻译工作，只要保证翻译高效正确即可，而且这个翻译过程非常繁琐、非常艰涩。对于这部分我感觉作为程序人员除了规范SQL格式，尽可能利用查询分析器可能存在的缓存减少、简化翻译过程没有太多可控性。可能DBA或者SQL Proxy会对这一块进行研读，比如360 Atlas开发人员。 优化器组件 同一个Query可以按照A路径执行也可以按照B路径执行，不同的执行路径会有不同的执行效率。同时请求到达存储引擎以后使用哪个索引这都严重影响执行的效率。访问路径和索引的选择要依赖对数据的统计所以这部分包含对数据库中的数据情况统计。这一部分是程序人员最需要的关注的，深入理解这部分将能为编写高效程序提供有力的保障。 缓冲组件 缓存是提升效率的一个核心手段，MySQL这个层面的缓存包括全局和引擎级别的缓存的管理。对这一块进行学习理解、尽可能的提高缓存的命中率，将能大大提升系统的性能。 插件式存储引擎 MySQL采用插件式存储引擎是其核心特点之一。不同存储引擎的选择将从根本上影响系统的特性和性能，对比了解各个存储引擎的特性和性能对系统建设是至关重要的。我们最长对比的Myisam和InnoDB引擎，随着时间的发展当前InnoDB基本一手遮天，后续详细梳理也将主要以InnoDB为主。 存储引擎负责着自己的内存管理、索引管理和数据的实际存储工作。 MySQL存储引擎是Table层面的 索引是由存储引擎管理维护的，其存储结构也是存储引擎决定的 物理文件 上文提到数据库是指一组按照特定数据模型组织的数据文件集合；这里的组件就是用于管理这些物理文件的，这部分功能基本上依靠存储引擎自己完成的。这部分包含的文件还有Redo、Undo Log，索引，Binary，ERROR、Slow、Query日志等。 这些文件的存储根据存储引擎不同可能有不同的差异，但是绝大多数情况还是依赖操作系统的文件系统；因为操作系统可以对数据库屏蔽不同的存储设备的差异，比如NTFS、ext、NAS、SAN等等。当然这也不是一定的，比如InnoDB就支持裸设备存储。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.beanmr.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.beanmr.com/tags/MySQL/"},{"name":"Architecture","slug":"Architecture","permalink":"http://blog.beanmr.com/tags/Architecture/"}]},{"title":"[回顾MySQL]思维导图","slug":"2016-6-13-about-mysql-mindmap","date":"2019-03-20T03:11:10.038Z","updated":"2019-03-20T03:50:14.059Z","comments":true,"path":"2016-6-13-about-mysql-mindmap/","link":"","permalink":"http://blog.beanmr.com/2016-6-13-about-mysql-mindmap/","excerpt":"","text":"转眼工作好几年了，MySQL一直是主力数据库；现在梳理一下自己MySQL方面的知识汇总成文。本文作为开篇主要是一张思维导图，后续文章将一一展开图中的个个知识点。 体系架构结构组成主要介绍MySQL服务器的组成组件和各部分的组件职责。 动态结构介绍查询请求是服务器主要的负载，这部分从一条Query SQL的执行过程介绍各个结构组件的作用及相关关系。 存储引擎MySQL被设计成插件式体系架构，插件式的存储引擎也是MySQL服务器区别于其它服务器的一个重要特征。本部分将比对介绍各个存储引擎的差异并解析各个对比指标在实际应用的中的意义，最终着重介绍选择InnoDB引擎的几个理由。 MySQL程序及管理工具将介绍MySQL服务器自带的程序及管理工具。 优化SQL语句优化本部分主要介绍一个SQL语句上的性能差异。 库结构优化一般的程序员关心语句，好的程序员关心数据结构。一个好的库表结构设计能给性能带来巨大的益处，本部分将介绍一些库表结构上的性能差异。 索引优化索引是提升效率的主要途径，一个好的索引能成倍的提高查询性能；但是一个坏的索引也可能给插入更新带来严重的效能消耗。索引基本是程序人员在数据库方面需要最精进的部分，这里会比较详细的介绍对比各种索引的情况，这里主要参照InnoDB引擎的索引进行介绍。 MySQL是插件式的！索引服务是由存储引擎决定的！ 针对InnoDB引擎优化将介绍一个关于InnoDB引擎的一些优化。 锁优化MySQL细节的锁管理由存储引擎实现的，锁一直是性能的杀手但是锁又是无法避免的。因为锁的情况受不同的隔离级别、不同的查询条件、MVCC等复杂条件的影响，这部分是非常难以掌握和理解的，这也是MySQL进阶的一个标志。这里将细节的阐述一些锁优化相关的内容，主要还是参考InnoDB引擎来介绍。 缓存优化缓存无处不在在MySQL中也一样，高命中率的缓存将大大提升服务器的查询性能。 查询优化器一条SQL只要正确执行了就能得到正确的执行结果，但是不同的执行方式却可能有巨大的性能差异。理解MySQL查询优化器，使SQL语句更加契合优化器的习惯，将大大的提升程序性能。 应用作为程序员最关注的还是怎么用好MySQL，这部分重要从应用的层面去介绍MySQL。包括了JDBC、连接池、SQL语言、横向扩展MySQL的应用适配内容。 数据库原理这部分将着重讲解一些数据库组成原理的基础学科内容，这将能帮我们更加好的理解MySQL。 高可用运维本人并不专注运维，但是在生产环境中做一些操作并不可以采用简单的SQL完成；这里介绍一些高可用运维发面的内容也是希望抛砖引玉让大家有一些了解工业应用和Demo是有本质区别的。 面试那些事最后和大家聊聊面试中常常遇见的一个问题，毕竟这是大家升职加薪最快的通道之一。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.beanmr.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.beanmr.com/tags/MySQL/"}]},{"title":"Java工程师要懂的硬件知识-CPU-2-指令执行","slug":"2016-2-26-a-hardware-view-for-java-cpu-2","date":"2019-03-20T03:11:10.037Z","updated":"2019-03-20T03:50:14.038Z","comments":true,"path":"2016-2-26-a-hardware-view-for-java-cpu-2/","link":"","permalink":"http://blog.beanmr.com/2016-2-26-a-hardware-view-for-java-cpu-2/","excerpt":"","text":"本文将按照从整体到局部的顺序一步步深入介绍现代CPU的结构组成；然后再在CPU简化结构的基础上，根据指令执行的过程一步步的分析CPU的执行阶段，并着重介绍指令流水线、乱序执行和分支预测这些广泛应用的优化技术及这些优化造成的冒险(Hazards)；最后再通过一段Java代码去印证所介绍的内容，去体会Java中的Mechanical Sympathy。 敬请期待以下内容：指令流水线指令执行与执行阶段CPU简化结构流水线执行乱序执行分支预测数据冒险/结构冒险Java中的CPU优化CPU相关知识分类梳理","categories":[{"name":"Fundamental","slug":"Fundamental","permalink":"http://blog.beanmr.com/categories/Fundamental/"}],"tags":[{"name":"Hardware","slug":"Hardware","permalink":"http://blog.beanmr.com/tags/Hardware/"},{"name":"CPU","slug":"CPU","permalink":"http://blog.beanmr.com/tags/CPU/"},{"name":"Instruction-PipeLine","slug":"Instruction-PipeLine","permalink":"http://blog.beanmr.com/tags/Instruction-PipeLine/"},{"name":"Out-Of-OrderExecution","slug":"Out-Of-OrderExecution","permalink":"http://blog.beanmr.com/tags/Out-Of-OrderExecution/"},{"name":"Branch-Prediction","slug":"Branch-Prediction","permalink":"http://blog.beanmr.com/tags/Branch-Prediction/"}]},{"title":"Java工程师要懂的硬件知识-CPU-3-Java与分支预测","slug":"2016-2-29-a-hardware-view-for-java-cpu-3","date":"2019-03-20T03:11:10.037Z","updated":"2019-03-20T03:50:14.040Z","comments":true,"path":"2016-2-29-a-hardware-view-for-java-cpu-3/","link":"","permalink":"http://blog.beanmr.com/2016-2-29-a-hardware-view-for-java-cpu-3/","excerpt":"","text":"本文将按照从整体到局部的顺序一步步深入介绍现代CPU的结构组成；然后再在CPU简化结构的基础上，根据指令执行的过程一步步的分析CPU的执行阶段，并着重介绍指令流水线、乱序执行和分支预测这些广泛应用的优化技术及这些优化造成的冒险(Hazards)；最后再通过一段Java代码去印证所介绍的内容，去体会Java中的Mechanical Sympathy。 Java中的分支预测本系列之前文章介绍了Java工程师应该了解的CPU相关的一些内容。本文将用一段Java代码去印证、分析上文中介绍的分支预测对Java程序的影响，去体会Java中的Mechanical Sympathy。 如下代码，准备一个随机数组成的数组作为测试对象，遍历数组并判断如果元素的值大于128则将此元素累加到sum之上。这样的场景在日常开发中非常常见，比如对某一批订单数据需要根据订单的来源和订单的类型的采用不同的流程分支去处理的需求。 演示程序将分别采用直接遍历，排序后遍历，条件分支语句代替if判断三种方式实现，并在Intel Core i7的Mac OS 10.11.3下采用默认安装的JDK1.8运行。本文将结合之前的内容分析耗时结果，希望各位也在自己的设备上加以验证并在评论中与大家分享自己的结果数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package com.beanmr.blog.javase.jvm.pipeline;import java.util.Arrays;import java.util.Random;/** * Desc:Branch-Prediction In Java Demo * ------------------------------------ * Author:beanmr * Date:16/2/20 * Time:下午11:04 */public class BranchPredictionTest &#123; public static void main(String[] args) &#123; // Generate data int arraySize = 32768; int data[] = new int[arraySize]; Random rnd = new Random(); for (int idx = 0; idx &lt; arraySize; idx++) data[idx] = rnd.nextInt(256); //do Sum without sort long start = System.nanoTime(); doSum(arraySize, data); long end = System.nanoTime(); System.out.println(\"Sum Without Sort : \" + (end - start) / 1000000000.0); long sortStart = System.nanoTime(); Arrays.sort(data); long sumStart = System.nanoTime(); doSum(arraySize, data); end = System.nanoTime(); System.out.println(\"Sort Cost : \" + (sumStart - sortStart) / 1000000000.0); System.out.println(\"Sum Cost : \" + (end - sumStart) / 1000000000.0); System.out.println(\"Sort&amp;Sum Cost : \" + (end - sortStart) / 1000000000.0); start = System.nanoTime(); doSumWithConditionalOp(arraySize, data); end = System.nanoTime(); System.out.println(\"Sum With ConditionalOp : \" + (end - start) / 1000000000.0); &#125; private static void doSum(int arraySize, int[] data) &#123; long sum = 0; for (int i = 0; i &lt; 100000; ++i) &#123;//amplify loop // Primary loop for (int idx = 0; idx &lt; arraySize; ++idx) &#123; if (data[idx] &gt;= 128) sum += data[idx]; &#125; &#125; System.out.println(\"sum = \" + sum); &#125; private static void doSumWithConditionalOp(int arraySize, int[] data) &#123; long sum = 0; for (int i = 0; i &lt; 100000; ++i) &#123;//amplify loop // Primary loop for (int idx = 0; idx &lt; arraySize; ++idx) &#123; sum += (data[idx] &gt;= 128 ? data[idx] : 0); &#125; &#125; System.out.println(\"sum = \" + sum); &#125;&#125; 敬请期待以下内容：结果解读分支预测条件语句","categories":[{"name":"Fundamental","slug":"Fundamental","permalink":"http://blog.beanmr.com/categories/Fundamental/"}],"tags":[{"name":"Hardware","slug":"Hardware","permalink":"http://blog.beanmr.com/tags/Hardware/"},{"name":"CPU","slug":"CPU","permalink":"http://blog.beanmr.com/tags/CPU/"},{"name":"Instruction-PipeLine","slug":"Instruction-PipeLine","permalink":"http://blog.beanmr.com/tags/Instruction-PipeLine/"},{"name":"Branch-Prediction","slug":"Branch-Prediction","permalink":"http://blog.beanmr.com/tags/Branch-Prediction/"}]},{"title":"解决GitHub Pages屏蔽百度爬虫的方法","slug":"2016-2-24-solve-github-baidu-spider-blocking","date":"2019-03-20T03:11:10.029Z","updated":"2019-03-20T03:50:14.016Z","comments":true,"path":"2016-2-24-solve-github-baidu-spider-blocking/","link":"","permalink":"http://blog.beanmr.com/2016-2-24-solve-github-baidu-spider-blocking/","excerpt":"","text":"Github屏蔽百度爬虫导致在Github Pages上托管的博客、网站都无法被百度索引到，但对于国内的小伙伴尤其是还在上学的未来的程序员们百度还是一个重要的检索渠道。已经有小伙伴在这方面做了尝试并且进行了全面的分析，这里我仅仅介绍一下个人的做法。这个博客也托管在Github Pages上，个人没有虚拟主机、域名也懒得备案，主要就是通过SAE的免费主机加智能DNS解决的。 新浪云开始征收每天10云豆（一毛钱）的最低租金，此方案不再严格完全免费。 但充值200元可以在新浪云代办网站备案，之后采用七牛方案也是个不错的选择。 文章关键点在于智能DNS的应用故保留此文章于此 可行性及原理分析已经有小伙伴在这方面做了尝试，文章从原理到实践写的很详尽。其主要思路是，希望通过CDN的缓存拦截百度爬虫访问Github服务器，防止百度爬虫到Github服务器被暴揍。但是从CDN的角度，各个厂商还专门发展搜索引擎自动回源所以人家本身就不是准备干这活的。最后小伙伴也采用了个人虚拟主机的方案而且提供了Github的Webhook自动部署实践的介绍。这位叫Jerry的小伙伴棒棒嗒！ 另外也有一部分使用七牛存储的小伙伴，尝试通过在七牛上保存网站的静态文件镜像来服务百度爬虫。主要的优势是七牛的流量和空间很足，只要充值10元就可以绑定自定义域名；但是死穴在于像我这种懒得备案的域名七牛不允许绑定。 小站最后采用了新浪云主机(SAE)+智能DNS(本人万网)+百度云CDN解决。思路上还是智能DNS针对来自百度解析线路的请求指向SAE服务器，SAE服务器保存Jekyll生成的静态文件当镜像。使用百度CDN的原因并不是为了加速，而是因为百度爬虫机器好像几乎不鸟万网的智能DNS，也就是说万网经常错误返回给百度默认的结果，但所幸对百度CDN的DNS同步做的很好所以加了这个中间层。 如果万网智能DNS很好用理想的路径如下： 添加了百度CDN以后的路径如下： 有趣的是百度云CDN有两个而且两个都是真的，一个是我用的免费的百度云加速另一个是百度云CDN。 操作手册 注册SAE的账号并创建一个PHP空应用；因为PHP的应用收费最低基本每天几个云豆，点我的连接注册送1000云豆够用好久了，我们只拿它当是一个Nginx服务器用。》》》点我注册啊《《《 从应用后台获取代码管理地址，我选用的是git仓库方式。用Github Pages的朋友没有不会的吧，注意因为SAE支持多版本部署所以push的时候要指定。 1git remote add sae https://git.sinacloud.com/应用名 1git push sae master:1 jekyll clean jekyll build 拷贝_site到SAE的git然后push 通过SAE的提供的应测试你的站点 http://应用名.applinzi.com/ 到百度云加速添加自己的网站 配置你的DNS服务并测试 手工同步部分：因为我做了文章和Jekyll源码的分离发布文章总要执行命令所以写了脚本","categories":[{"name":"Jekyll","slug":"Jekyll","permalink":"http://blog.beanmr.com/categories/Jekyll/"}],"tags":[{"name":"github","slug":"github","permalink":"http://blog.beanmr.com/tags/github/"},{"name":"seo","slug":"seo","permalink":"http://blog.beanmr.com/tags/seo/"}]},{"title":"Java工程师要懂的硬件知识-CPU-1-基础","slug":"2016-2-20-a-hardware-view-for-java-cpu-1","date":"2019-03-20T03:11:10.012Z","updated":"2019-03-20T03:50:14.041Z","comments":true,"path":"2016-2-20-a-hardware-view-for-java-cpu-1/","link":"","permalink":"http://blog.beanmr.com/2016-2-20-a-hardware-view-for-java-cpu-1/","excerpt":"","text":"本文将按照从整体到局部的顺序一步步深入介绍现代CPU的结构组成；然后再在CPU简化结构的基础上，根据指令执行的过程一步步的分析CPU的执行阶段，并着重介绍指令流水线、乱序执行和分支预测这些广泛应用的优化技术及这些优化造成的冒险(Hazards)；最后再通过一段Java代码去印证所介绍的内容，去体会Java中的Mechanical Sympathy。 CPU分层架构基础硬件知识一般认识中的CPU就是主板插槽上那个很多针脚的小方块。对于PC服务器常常会有“2U2路12核24线程”这样的描述，现在参照下面图片中的“戴尔 PowerEdge R730”来解读。 “2U”指的是这台服务器在机架上占用2个U位置，也就是这台服务器个头有2个单位那么大；“2路”指的是主板上有两个CPU插槽可以插2个CPU实体；“12核”是针对其使用的E5-2620处理器，每颗拥有6个CPU内核，2路也就是12颗内核；另外因为超线程技术所以操作系统中我们可以看到24个CPU逻辑内核也就是24线程。 更近一步的去观察，去观察硬件的组织结构，如下图： 图中有两颗CPU每颗CPU上挂载了4条DDR内存条作为各自的主存储，然后两颗CPU之间通过QPI总线连接，这就是上一篇中介绍的NUMA结构的实例。整个结构通过QPI总线与一颗叫做Intel C600的芯片连接，这颗芯片提供着SAS,SATA,PCIe,DMI,USB等IO接口的控制服务。 再进一步的走到CPU内部就是如下图所示的一片在硅晶上的电路，其实硅晶是面积远小于平时看到的CPU大小。硅晶电路板上的对外连接点会被用导线连接到引脚让，然后用绝缘塑料或者陶瓷进行打包保护，这就是我们常说的封装技术。感兴趣的可以去看一下Intel工厂之旅之类的纪录片有一个感性的理解。 进一步观察CPU电路板，这颗CPU电路的可以由以下各个组件构成，这些组件在上一篇中都有介绍有兴趣的小伙伴可以回看一下。 最后说一句E5系列的CPU的L3缓存从表面看是一个整体，其实在这次架构设计中Intel加入L3分块的优化设计。原理我们不深究在这里只是提醒一下这个优化的思路是不是跟NUMA有点像。 分层结构/指令集/微架构重新回归到抽象的CPU世界，CPU体系也不是一个整体结构而是跟我们Java经典三层架构一样是分层。 首先最上层是指令集，大的分类有精简指令集(RISC)，比如MIPS、ARM、Power Architecture指令集；复杂指令集CISC，如最经典的x86/x86-64指令集。指令集约定了CPU能完成的一系列的动作，比如ADD加法指令、MOV传送指令等。有了这一些列的指令就支撑起来了一门编程语言也就是常说的汇编语言，因此同样基于x86汇编的程序我们可以运行于Intel的处理器上也可以运行于AMD的处理器上。指令集保证了软件的兼容性，这也就是为什么我国自主知识产权的处理器“龙芯”要去购买MIPS指令集的授权，软硬件系统是一个庞大的生态体系，而指令集就是这个体系中的纽带。 虽然“龙芯”使用的MIPS指令集，生产也是意法半导体（ST）来代工的；但是我们说它是有自主知识产权的，就是因为它有自己的“GS464E”微架构。微架构就是某个指令架构下的一种实现结构设计，同样的指令集有不同的微架构、每种微架构最终可以有不同的电路实现和电路配置也就有了不同的CPU型号产品。 指令集-&gt;微架构-&gt;硬件实现，这就是CPU体系的一个分层结构。作为一个Java工程师虽然不必要深入了解每个层次的细节，但是至少要在头脑中有这样的一个体系以便于形成自己的知识体系和问题处理能力。","categories":[{"name":"Fundamental","slug":"Fundamental","permalink":"http://blog.beanmr.com/categories/Fundamental/"}],"tags":[{"name":"Hardware","slug":"Hardware","permalink":"http://blog.beanmr.com/tags/Hardware/"},{"name":"CPU","slug":"CPU","permalink":"http://blog.beanmr.com/tags/CPU/"},{"name":"Instruction-PipeLine","slug":"Instruction-PipeLine","permalink":"http://blog.beanmr.com/tags/Instruction-PipeLine/"},{"name":"Out-Of-OrderExecution","slug":"Out-Of-OrderExecution","permalink":"http://blog.beanmr.com/tags/Out-Of-OrderExecution/"},{"name":"Branch-Prediction","slug":"Branch-Prediction","permalink":"http://blog.beanmr.com/tags/Branch-Prediction/"}]},{"title":"[工具]如何访问Google-戏说VPN及路由VPN分流","slug":"2016-1-03-surf-internet-scientifically","date":"2019-03-20T03:11:09.937Z","updated":"2019-03-20T03:50:14.035Z","comments":true,"path":"2016-1-03-surf-internet-scientifically/","link":"","permalink":"http://blog.beanmr.com/2016-1-03-surf-internet-scientifically/","excerpt":"","text":"估计大多数老外觉着这个命题就如“怎么吸气?”一样无从回答吧！但在咱这儿，这是门手艺！不让访问推，不让访问非死不可都无所谓了；虽然不让用Gmail有点别扭咱也忍啦！但实在受不了熊厂搜索L1 Cache冒出来的结果都是CPU多少钱啊！接着折腾白话一下这个东西是什么，主要是面向完全不懂的小白童靴，已经不纯的请直接跳过。 如何科学上网这个话题的由来已经烂大街了，但我还是要表达一下我的态度。 面对现实的说,实际国情的确是很大一部分人民教育水平不高，对信息的判别能力有限容易受到煽动。这一点从微信上每天被转发的各种黄色新闻(别YY这是个新闻学术语)得到有力的印证。因此有这么一个保护性的监控机制也是非常正当合理的，其实各个国家都有这样的玩意甚至某些国家做的更先进更NB。我觉着人们的坏情绪并不应该是因为有这个玩意，而是因为这个玩意背后的简单粗暴的逻辑。希望以后这个玩意能更细腻更人性化。 科学上网是为了学习交流，要对知识交流饱含好奇心。 但更要把握好自己的好奇心，防止被用心险恶之人利用。 科学上网比较舒服的方式就是花点钱弄个VPN这是大家的共识，我觉着为了学习花点钱还是值得的。 VPN这个东西的原理就好比，你住在男生宿舍楼在门口有宿舍管理员大妈，你想和外面的朋友传递消息都要经过这个大妈。有的楼大妈比较温和，她记录下你说的每一句话干的每一件事，万一出了问题再拿着这一堆证据找你喝茶。而我们门口这个大妈可能是脾气暴躁一点，她可能认为任何与某些女生宿舍楼交流的情况都是鸡鸣狗盗、私通羞羞。这个打击面就有点大，这误伤了我们和某些同学之间纯洁的学习交流之需，所以我们才需要学习科学上网。正常情况我们和大妈说的是同一种语言，这个时候大妈就知道你想交流的这个人（可能是不太听大妈的话或者过去的罪过大妈）在她的印象中是坏孩子；但是如果我们在外面有一个卧底（大妈并没有关注她），她和你约定了一种大妈听不懂的暗号（加密），等暗号到了她那再由她翻译并转交给你目标对象，这样我们就可以无阻碍的交流了！VPN就是这样一个交流的通道和交流的方式。 所以我们的VPN需要在外面有个接应的同志，这个接应的同志一般可以选择直接购买别人搭建好的情报网络使用权，也可以自己在外面建立一个据点培养一个自己的同志。前一种就是直接购买VPN账号，后一种就是租借外面的主机自己搭建VPN服务器。如果自己在外面还有博客、应用一类的需求可以考虑购买一个VPS自建，否则的话我觉着租借别人比较专业的情报网络比较合适。 等你和外面的卧底建立了联系，接下来的问题就是这个文章的重点了。你除了和外面的世界沟通，更多的时候是和身边的人沟通，但是默认情况下有了VPN所有的流量都会从她那里走。这就好比如你在女生宿舍安插了一个卧底想方便和女性朋友沟通；但实际情况却变成了说的每一句话都要变成密码，先走到女生宿舍卧底那里然后再转达出去；这样就严重影响了你和下铺兄弟沟通的速度，更不爽的是跟卧底说话是要按流量收钱的。 为了解决这个问题我们可以使用一个叫路由表的东西，这个东西在计算机收到你想交流的需求的时候，可以先去查一下你要交流的对象是在女生宿舍楼还是你下铺，然后再决定是否通过你的卧底。这样不就可以加速又省钱了嘛！当然网上也已经有人做了工具chnroutes,它的原理就是先从一个地方弄到所有你可能沟通的对象的房间号，然后在你真正去交流之前先查一下你要的对象是在男生宿舍楼还是女生宿舍楼，如果在男生宿舍楼就不走卧底这条线了。从而实现了即节省VPN流量费又加速了内部访问的效果。 仅仅是戏说，举个例子让大家方便理解，不严谨不科学还请大家斧正。 因为VPN供应商鱼龙混杂而且有很多伪造云梯的钓鱼网站，有需要的可以通过我的推荐链接购买，不用担心被钓鱼而且更享受10元优惠。","categories":[{"name":"Tools","slug":"Tools","permalink":"http://blog.beanmr.com/categories/Tools/"}],"tags":[{"name":"VPN","slug":"VPN","permalink":"http://blog.beanmr.com/tags/VPN/"}]},{"title":"Java工程师要懂的硬件知识-前言","slug":"2016-1-14-a-hardware-view-for-java-preface","date":"2019-03-20T03:11:09.937Z","updated":"2019-03-20T03:50:14.036Z","comments":true,"path":"2016-1-14-a-hardware-view-for-java-preface/","link":"","permalink":"http://blog.beanmr.com/2016-1-14-a-hardware-view-for-java-preface/","excerpt":"","text":"Mechanical Sympathy这个短语描述了一种车手对汽车天生的感觉，也是Martin Thompson大牛的博客标题。从并发编程网Disruptor的介绍中注意到这个短语，再去品位Martin对它的简短阐述’Hardware and software working together in harmony’的确很有道理。在对任何语言的深入学习研究中，总逃不过对底层硬件的了解与学习，很多语言的特性、行为在硬件的角度去观察就很容易解释了；同时在追求语言的更高性能的过程中，也要更多去了解硬件的知识，让软件更加匹配硬件的特性、更好利用硬件的优化才能获得更高的优化效果。 概述硬件工程师的杰作互联网的繁荣是建立在硬件工程师的伟大杰作之上的。使硬件更加高效的一个途径是提高硬件的运行速度，另外一个途径就是让可以任务并行起来；随之而来的就是缓存、并发、同步等一些列设计和优化。现代计算机的异步特性加之这些优化使得软件系统在多线程的情况下常常出现背离程序直觉的情况。作为一个高级语言开发者了解硬件就是为去感受Mechanical Sympathy，去了解硬件工程师的用心良苦从而让软件与硬件更加匹配。 讲故事要从开头说，在很早很早以前有一位叫图灵的先生画了一个盒子，这个盒子就一直把人们圈到了现在，这就是图灵机模型。 这个盒子有一条纸带和一个规则表格还有一个内部状态存储，当然还有一个用来读、写纸带的读写头。整个过程模拟了人类在算草纸进行运算的过程：在纸上写或擦除一个符号；将注意力从一个位置转移到另外一个位置。 言归正传虽然现代计算器体系还在这个圈圈之中，但是整体的结构已经变得极度复杂了。下图是一个CPU的逻辑组成(物理上并不是都在CPU里)，它作为整个计算机系统的大脑，负责着处理所有类型数据的运算工作(其实还有各式各样的协处理器帮忙)，这也是软件工程师关注的计算机系统核心模型。它主要有CU,MU,ALU,IO四个子系统组成,看似简单的四个框框其实每个都涵盖了N个复杂的结构。 Memory Unit简单说内存和存储单元(MU)就是负责保存各种数据的部分，它也称为内部存储/主存储/RAM。RAM的名称来自其硬件特性随机访问，内部存储/主存储的名称来自相对于硬盘等通过IO系统访问的存储而言的。注意这里说的是CPU的逻辑组成，MU指的并不仅仅是CPU内部的存储部件还应该涵盖了内存。 MU负责存储的有以下数据： 处理过程中，所需的所有数据和指令 处理过程中，产生的中间结果 已处理完成，但尚未通过输出设备发布的数据 经输入/输出设备，要进入/输出的所有主内存数据 MU功能看似简单但这一块却是Java工程师最需要关注的部分。众所周知各种存储部件的速度有很大差别，为了匹配高速运行的运算核心并很好的平衡成本，硬件工程师在这里设计了多层的缓存系统。也因为存储系统及IO系统的延迟，为了更好的发挥硬件能力，硬件工程师在这里设计了指令乱序、回写缓冲等等。 先给出一张Intel的Sandy Bridge微架构处理器的MU示意图，让大家对MU的缓存系统组成和各个部分的访问速度有一个直观的印象。 从图中看到整个MU由每个核心独享的寄存器,读取缓冲，存储缓冲,L1 Cache,L2 Cache；同插槽核心共享的L3 Cache以及一个跨插槽的NUMA结构组成。NUMA是每个插槽独享的内存控制器(MC)及MC分配到的内存和连接插槽通信的QPI总线组成的。 在这些不同核心的缓存之间存在着硬件连线，通过MESI/MESIF/MOESI协议，QPI总线或HT总线保证缓存的一致性。现在网上经常出现对这一块误解的文章，从缓存不一致角度去解释多线程的某些一致性问题；新手要认识到MU的这些缓存在硬件上都已经保证了一致性不要被误导。 图中标注了每种存储访问的延迟，从最小的1个CPU节拍到跨插槽内存访问时QPI延迟+DRAM访问延迟大致100ns左右的延迟，各级访问速度的差异显而易见。这里的优化一般考虑尽可能命中缓存、降低缓存间一致性协议通信流量的方案。 直观的看对于一颗频率为3G的CPU核心，因为流水线(Pipeline)技术每CPU节拍可以并行执行[4条指令][^2]；1ns就有3个节拍也就是每颗核心能并行执行12条指令，可以想象跑一趟主存就可能要耽误1200条指令，而且这个延迟还从10-100纳秒不一定。在等待这个延迟的时候CPU就什么都不做吗？硬件工程师在这里设计了乱序执行，这样就可以很大限度的隐藏这个延迟了。 由此可见这里对于软件工程师提升性能有多大的发挥空间，软件工程师的Mechanical Sympathy就是在这些细节中展现出的力量。相反这里提到的乱序能很大隐藏延迟，但它也是无数程序员都踩过的深坑，在多线程编程中迷糊了无数人。天下没有免费的午餐！作为一个Java工程师去学习硬件知识可以更好的理解多线程编程、可能大大提升程序的响应速度，但如果平时工作中太纠结于这些硬件细节又会迷失忘却作为一名高级语言开发者最重要的开发效率。 ALU(Arithmetic Logic Unit)算数逻辑运算单元(ALU)由算数运算单元(AU)和逻辑运算单元(LU)组成。 算数运算单元主要完成各种数学运算，也就是加、减、乘、除等运算。在这一块的优化一般就是推荐尽量使用AU擅长的加法、移位运算，比如使用移位运算代替乘法运算、在二维坐标系求两点距离尽量直接使用未开方运算的数值等。 上述内容在组原教材中有明确的记载大家也很理解和认同。的确在早期的CPU中乘法运算相对加法运算非常耗时，但是随着技术的发展越来越多的CPU整合了数学协处理器，现在差距可能不是那么悬殊了。协处理器就好比CPU的一个小弟，因为其电路是专为某种行为设计的所以在特定操作上比通用处理器速度更快。当CPU遇到某个复杂的运算时会将这个运算交给协处理器完成从而提升整体的速度。这里提到协处理并不是说我们没有必要进行优化了，而是提醒刚刚毕业的小鲜肉们技术日新月异，有的时候我们的教材不一定适用了不要墨守成规，像这样的例子更极端的还有Java(32位JVM测试)里面short运算比int运算更慢。 逻辑运算单元(LU)就是完成逻辑运算的组件，例如比较、判断、匹配及归并数据(comparing, selecting, matching and merging of data)。 Control Unit控制单元(CU)负责操作计算机的所有部件协调的工作，它并不直接参与到数据处理、读写过程而是指挥、协调组件完成数据处理。 CU主要完成以下功能： 控制数据流和指令流在其它系统中的流转 从MU中获取指令、翻译指令并根据指令操作计算机的完成指令 控制和协调其它单元的工作 控制IO单元进行数据的输入输出 作为一个Java工程师本人对这一块的了解也不是很深入，写在这里也是希望抛砖引玉盼望有朋友能给出一两个这一块优化的实例。 IO系统IO系统负责着与外部设备通信，对于Java工程师最常见的就是文件系统访问、数据库访问、网络服务等。这一块延迟相对MU延迟可能是非常大数字，所以作为一个Java工程师这也许是我们使用多线程编程最重要的原因，让程序在IO等待期间并行起来充分利用系统的计算能力。配合多线程还有批量处理、NIO等技术，总之一个应用响应时间出现问题最常见的就是IO占用的时间比非常高而且还是阻塞等待。 小节本节非常概括的介绍了CPU基本逻辑组成和一些技术名词；一方面是希望使大家在后续讨论中对这些名词不是很陌生，另外主要的目的还是为新手提供一个参考的概览图，希望在后续讨论过各种局部技术后能为其形成自己的知识体系有一点帮助。 限于个人技术能力、见识限制，还望各位看官不吝赐教。 参考 http://www.tutorialspoint.com/computer_fundamentals/computer_cpu.htm https://www.doc.ic.ac.uk/~wl/teachlocal/arch2/ http://ifeve.com/from-javaeye-cpu-cache/ http://ifeve.com/cpu-cache-flushing-fallacy-cn/ [^2]: 4条指令这个数字是教材数据并不准确实际可能为流水线级数(PipeLine Stage)，Intel早就达到了21级流水线所以这个数字可能大于等于21。","categories":[{"name":"Fundamental","slug":"Fundamental","permalink":"http://blog.beanmr.com/categories/Fundamental/"}],"tags":[{"name":"Hardware","slug":"Hardware","permalink":"http://blog.beanmr.com/tags/Hardware/"}]},{"title":"[算法]检查元素存在于集合-Bloom Filter/Counting Bloom Filter算法简介","slug":"2015-1-08-CheckExisting-BloomFilter","date":"2019-03-20T03:11:09.936Z","updated":"2019-03-20T03:50:14.040Z","comments":true,"path":"2015-1-08-CheckExisting-BloomFilter/","link":"","permalink":"http://blog.beanmr.com/2015-1-08-CheckExisting-BloomFilter/","excerpt":"","text":"判断某个元素是否在集合中是开发中常见的一个问题。如果数据集合比较小常用的查找、遍历，数据库查询等方式还可用，但是在缓存是否命中这种效率敏感的高频调用或者爬虫目标URL判重、大流量活动参与者判重等海量元素或高度并发场景（对误判有一定容忍）这种方式也许就不再可接受。 Bloom Filter算法算法描述误报及误报率最优的哈希函数个数位数组个数特性应用实例扩展及应用参考","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://blog.beanmr.com/categories/Algorithm/"}],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://blog.beanmr.com/tags/Algorithm/"},{"name":"CheckExisting","slug":"CheckExisting","permalink":"http://blog.beanmr.com/tags/CheckExisting/"},{"name":"BloomFilter","slug":"BloomFilter","permalink":"http://blog.beanmr.com/tags/BloomFilter/"}]},{"title":"[实践]使用JarJar优雅的发布依赖包","slug":"2015-1-08-Export-Jar-Gracefully","date":"2019-03-20T03:11:09.936Z","updated":"2019-03-20T03:50:14.042Z","comments":true,"path":"2015-1-08-Export-Jar-Gracefully/","link":"","permalink":"http://blog.beanmr.com/2015-1-08-Export-Jar-Gracefully/","excerpt":"","text":"作为服务需求方每次在项目中添加一个依赖都提心吊胆，怕新依赖会引入Jar包冲突、ClassNotFound问题。甚至有时新依赖使用的第三方包与项目中已有的版本完全不兼容，这就迫使需求方或冲突方不得不重新修改项目。因此如何为使用者发布一个第三方依赖尽可能少的包，体现了一个服务提供者的友好态度。 使用JarJar重封装减少发布包的依赖Spring框架体积庞大、功能繁杂但是它的第三方依赖仅仅只有Commons Log这是如何做到的呢？ 其实在Spring的实现中也大量了使用cglib，asm等工具包，但是 Spring 并没有直接引入依赖，而是采用将某个版本的 Jar 重新打包到自己的 package 之下的方式引入依赖。这相当于将工具包的代码拷贝到自己的项目中，使工具包里面所有类的包名都在自己的命名空间之下，从而避免了自己和其它依赖共同工具包项目之间的冲突。如果真的通过拷贝源文件实现重新发包，恐怕这个修改会非常繁琐而且容易出错。 通过 Spring 的 API 文档可以清楚的看到这一点： Spring使用了 Jar Jar Links 实现这个功能。 build.gradle12345678910111213141516171819202122task cglibRepackJar(type: Jar) &#123; repackJar -&gt; repackJar.baseName = \"spring-cglib-repack\" repackJar.version = cglibVersion doLast() &#123; project.ant &#123; taskdef name: \"jarjar\", classname: \"com.tonicsystems.jarjar.JarJarTask\", classpath: configurations.jarjar.asPath jarjar(destfile: repackJar.archivePath) &#123; configurations.cglib.each &#123; originalJar -&gt; zipfileset(src: originalJar) &#125; // repackage net.sf.cglib =&gt; org.springframework.cglib rule(pattern: \"net.sf.cglib.**\", result: \"org.springframework.cglib.@1\") // as mentioned above, transform cglib\"s internal asm dependencies from // org.objectweb.asm =&gt; org.springframework.asm. Doing this counts on the // the fact that Spring and cglib depend on the same version of asm! rule(pattern: \"org.objectweb.asm.**\", result: \"org.springframework.asm.@1\") &#125; &#125; &#125;&#125; JarJar介绍JarJarLinks可以很方便的重新打包并封装到自己的发布中，这样做有两大好处： 便捷的创建一个无依赖的单一文件的发布 避免自身对特定版本包的依赖造成的与其它程序冲突 JarJar包含一个继承于内建jar任务的Ant Task完成代码正常的打包工作，通过zipfileset元素指定内嵌的jar 文件，另外添加了一个新的规则配置用来描述内嵌 jar 文件的重命名规则。JarJar使用ASM进行bytecode转换方式来实现变更reference操作，并且提供一个特殊的handling来迁移资源文件和进行字符串字面量的转换工作。 JarJar应用示例基于Ant使用JarJar一般情况下我们在Ant会引入如下的task12345&lt;target name=\"jar\" depends=\"compile\"&gt; &lt;jar jarfile=\"dist/example.jar\"&gt; &lt;fileset dir=\"build/main\"/&gt; &lt;/jar&gt;&lt;/target&gt;使用JarJarLinks我们可以使用以下配置代替上面功能，因为jarjar`task本身继承于内建的jar任务。通过fileset指定的class文件可以被打包起来，如果仅仅将其它项目的class文件内嵌到自己的项目中并不能解决Jar Hell问题，因为此时类文件依旧保持着原有的名字。 我们可以通过 zipfileset 指定将其它项目的文件包含到自己的项目发布中，为了描述重命名的需求JarJar提供了一个Pattern配置来实现。 1234567891011&lt;target name=\"jar\" depends=\"compile\"&gt; &lt;taskdef name=\"jarjar\" classname=\"com.tonicsystems.jarjar.JarJarTask\" classpath=\"lib/jarjar.jar\"/&gt; &lt;jarjar jarfile=\"dist/example.jar\"&gt; &lt;fileset dir=\"build/main\"/&gt; &lt;!-- 包含一个第三方 jar 到项目中 --&gt; &lt;zipfileset src=\"lib/jaxen.jar\"/&gt; &lt;!-- JarJar 提供了一个Pattern配置用来描述重命名--&gt; &lt;rule pattern=\"org.jaxen.**\" result=\"org.example.@1\"/&gt; &lt;/jarjar&gt;&lt;/target&gt; 在上述的实例中我们将jaxen.jar 打包到自己的发布中，并且将以org.jaxen为开头的*包及其子包*的内容重命名到org.example之下。Pattern 中的*匹配任意有效包的子字符串，如果匹配单一的子包可以使用表示并且通过.来分隔。@1表示第一个匹配，@2依次排列，@0`可以用来表示整个匹配串。(这一块该怎么解释更明白呢？看Spring的配置吧！) 基于Gradle使用JarJar12345678910dependencies &#123; // Use jarjar.repackage in place of a dependency notation. compile jarjar.repackage &#123; from 'com.google.guava:guava:18.0' classDelete \"com.google.common.base.**\" classRename \"com.google.**\" \"org.private.google.@1\" &#125;&#125; 基于命令行使用JarJar command-line1java -jar jarjar.jar [help]help1java -jar jarjar.jar strings &lt;cp&gt;Dumps all string literals in classpath1java -jar jarjar.jar find &lt;level&gt; &lt;cp1&gt; [&lt;cp2&gt;]这个命令可以用来构建两个classpath 之间的依赖关系，level可以使class或者jar。如果不存在cp2，则表示使用cp1代替。转换Jar1java -jar jarjar.jar process &lt;rulesFile&gt; &lt;inJar&gt; &lt;outJar&gt;这个命令可以讲inJar中的内容转移到outJar中，outJar内容将全部被删除。 classpath属性是一组冒号或者分号分隔的文件夹、jar、zip文件。rules支持Mustang-style通配符描述。 在Maven中实现JarJar功能Maven提供了一个 Plugin 来实现JarJar功能12345678910111213141516171819202122232425262728293031323334353637&lt;dependency&gt; &lt;groupId&gt;org.sonatype.plugins&lt;/groupId&gt; &lt;artifactId&gt;jarjar-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;jarjar-version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- ...... --&gt;&lt;plugin&gt;&lt;groupId&gt;org.sonatype.plugins&lt;/groupId&gt;&lt;artifactId&gt;jarjar-maven-plugin&lt;/artifactId&gt;&lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jarjar&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;includes&gt; &lt;include&gt;asm:asm&lt;/include&gt; &lt;include&gt;org.sonatype.sisu.inject:cglib&lt;/include&gt; &lt;/includes&gt; &lt;rules&gt; &lt;rule&gt; &lt;pattern&gt;org.objectweb.asm.**&lt;/pattern&gt; &lt;result&gt;com.google.inject.internal.asm.@1&lt;/result&gt; &lt;/rule&gt; &lt;rule&gt; &lt;pattern&gt;net.sf.cglib.**&lt;/pattern&gt; &lt;result&gt;com.google.inject.internal.cglib.@1&lt;/result&gt; &lt;/rule&gt; &lt;keep&gt; &lt;pattern&gt;com.google.inject.**&lt;/pattern&gt; &lt;/keep&gt; &lt;/rules&gt; &lt;/configuration&gt; &lt;/execution&gt;&lt;/executions&gt;&lt;/plugin&gt;","categories":[{"name":"Tools","slug":"Tools","permalink":"http://blog.beanmr.com/categories/Tools/"}],"tags":[{"name":"JarHell","slug":"JarHell","permalink":"http://blog.beanmr.com/tags/JarHell/"},{"name":"Gracefully","slug":"Gracefully","permalink":"http://blog.beanmr.com/tags/Gracefully/"}]},{"title":"[JVM]深入Java对象内存布局-01-基础工具Unsafe","slug":"2015-1-06-DiveIntoJvm-ObjectMemoryLayout","date":"2019-03-20T03:11:09.935Z","updated":"2019-03-20T03:50:14.035Z","comments":true,"path":"2015-1-06-DiveIntoJvm-ObjectMemoryLayout/","link":"","permalink":"http://blog.beanmr.com/2015-1-06-DiveIntoJvm-ObjectMemoryLayout/","excerpt":"","text":"IDEAJava平台屏蔽了内存管理的细节，为开发人员提供了一个安全便捷的企业级应用的开发基础。但是在深入学习和应用Java的过程中，我们由于种种的特殊应用场景的需求又希望了解Java底层内存管理某些细节；这其中有一个问题就是Java的对象在内存到底是怎么一种存在形式。已经有很多文章从Java/JVM Specification的角度阐述了这个问题，但很少有文章从一个个实例展示这些规范的落地，从而使得很多朋友读的云里雾里。这次本文就以一个个运行于JVM中真实的Java对象实例为切入点，展示这一个个规范的落地与Hotspot虚拟机对象内存布局。 大家都知道无论任何东西，在内存中最终都是一连串的0/1的二进制字串，所以最直观的最真实的了解Java对象内存布局的方式，就是将真实的对象实例在内存中的二进制表示一位位的读出来研究与学习。但是众所周知Java为我们屏蔽了繁琐的内存管理和操作问题，所以我们第一步要考虑的问题就是如何读取JVM中的内存中想要的字节，这也是本篇博文的主要内容。为了后续关于对象内存分布的讨论，我们此次先解决以下几个问题。 如何在Java环境进行JVM中的内存操作 如何获取Class对象的内存信息 如何获取一个Object对象的内存信息 使用Unsafe进行内存操作Java提供了一个sun.misc.Unsafe类，它并不是JavaSE的一部分，它更类似于Java这一安全平台的一个后门。透过这个类我们可以实现对JVM中内存的直接操作和一些线程低层次控制功能。正如其名字表达的含义一样这一切都是Unsafe的，是强烈不建议在应用开发中使用的，但在一些基础的数据结构或者线程工具类中我们却常常看到它的身影。这里我们应用它主要完成获取对象的起始地址和读取指定地址内容 如何获取Unsafe实例关注如下Unsafe中的代码：构造参数私有化；类持有一个自身实例的私有field但Getter方法被限制访问。 123456789101112131415161718192021222324private static native void registerNatives();static &#123; // 调用native方法 registerNatives(); // 将getUnsafe加入到Reflection的过滤列表中 这个方法不能通过反射访问 sun.reflect.Reflection.registerMethodsToFilter(Unsafe.class, \"getUnsafe\");&#125;// 私有的构造方法 不能通过new进行实例化private Unsafe() &#123;&#125;// 类持有一个自身的实例 这就是我们获取此类实例的基础 通过反射窃取此实例// 这种方式也是单例模式等限制实例化的常用手段private static final Unsafe theUnsafe = new Unsafe(); @CallerSensitivepublic static Unsafe getUnsafe() &#123; // 判断此方法的调用方有系统权限 基于调用者的类加载为null确定的 // 也就是只有被系统加载器加载类能访问 非受信代码调用会出现SecurityException // 这也是获取Unsafe实例的一个方案：通过一个由系统加载的工具类调用这个方法返回实例 Class&lt;?&gt; caller = Reflection.getCallerClass(); if (!VM.isSystemDomainLoader(caller.getClassLoader())) throw new SecurityException(\"Unsafe\"); return theUnsafe;&#125; Unsafe方法的简介如何通过Unsafe获取对象的地址###获取Class对象的地址 ###获取对象实例的地址 读取内存中的对象","categories":[{"name":"JVM","slug":"JVM","permalink":"http://blog.beanmr.com/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://blog.beanmr.com/tags/JVM/"},{"name":"MemoryLayout","slug":"MemoryLayout","permalink":"http://blog.beanmr.com/tags/MemoryLayout/"}]},{"title":"ReviewBoard LDAP 配置 验证失败 python-ldap安装失败","slug":"2014-8-12-ReviewBorad-LDAP-trobleshooting","date":"2019-03-20T03:11:09.935Z","updated":"2019-03-20T03:50:14.028Z","comments":true,"path":"2014-8-12-ReviewBorad-LDAP-trobleshooting/","link":"","permalink":"http://blog.beanmr.com/2014-8-12-ReviewBorad-LDAP-trobleshooting/","excerpt":"","text":"ReviewBoard配置LDAP无效之前配置代码评审工具选定了淘宝的Tao-ReviewBoard，配合使用Reviewboard 1.6.19的版本。（当前Tao-ReviewBoard发布v1.1.0支持ReviewBoard 1.7） 系统运行在Centos 5.8之上；系统自带Python2.4 升级为Python2.7. openldap直接通过yum安装版本为2.3.43，依赖包及devel全部安装（opnldap openldap24-libs openldap-clients openldap-devel openssl-devel libgsasl libgsasl-devel,本机LDAP Server有openldap-servers）。 最近整合LDAP真是各种闹心，但是一旦配置完成的确是很便捷。 配置LDAP过程历经磨难，先后出现了3个问题，记录于此以备后查： python-ldap安装失败 ReviewBoard绑定LDAP失败(问题有点蠢) ReviewBoard验证LDAP信息失败 调试过程开启openldap日志功能 python-ldap安装失败，一直报错头文件异常 使用yum info python-ldap可以看到系统为python2.4安装了python-ldap，但是在python2.7的site-packages中没有。 1easy_install-2.7 install python-ldap 安装一直失败，也参照了网上同学的一些[办法](http://nilm61.iteye.com/blog/1779136)依旧无解，大致的异常如下： 1234567891011121314151617181920212223242526272829extra_compile_args: extra_objects: include_dirs: /opt/openldap-RE24/include /usr/include/sasl /usr/includelibrary_dirs: /opt/openldap-RE24/lib /usr/liblibs: ldap_rfile Lib/ldap.py (for module ldap) not foundfile Lib/ldap/controls.py (for module ldap.controls) not foundfile Lib/ldap/extop.py (for module ldap.extop) not foundfile Lib/ldap/schema.py (for module ldap.schema) not foundwarning: no files found matching 'Makefile'warning: no files found matching 'Modules/LICENSE'file Lib/ldap.py (for module ldap) not foundfile Lib/ldap/controls.py (for module ldap.controls) not foundfile Lib/ldap/extop.py (for module ldap.extop) not foundfile Lib/ldap/schema.py (for module ldap.schema) not foundfile Lib/ldap.py (for module ldap) not foundfile Lib/ldap/controls.py (for module ldap.controls) not foundfile Lib/ldap/extop.py (for module ldap.extop) not foundfile Lib/ldap/schema.py (for module ldap.schema) not foundIn file included from Modules/LDAPObject.c:18:/usr/include/sasl/sasl.h:349: 警告：函数声明不是一个原型Modules/ldapcontrol.c: In function ‘encode_assertion_control’:Modules/ldapcontrol.c:352: 警告：隐式声明函数 ‘ldap_create_assertion_control_value’Modules/constants.c: In function ‘LDAPinit_constants’:Modules/constants.c:155: 错误：‘LDAP_OPT_DIAGNOSTIC_MESSAGE’ 未声明 (在此函数内第一次使用)Modules/constants.c:155: 错误：(即使在一个函数内多次出现，每个未声明的标识符在其Modules/constants.c:155: 错误：所在的函数内只报告一次。)Modules/constants.c:365: 错误：‘LDAP_CONTROL_RELAX’ 未声明 (在此函数内第一次使用)error: Setup script exited with error: command 'gcc' failed with exit status 1 也有网上的童鞋直接修改报错的头文件声明一个变量，虽然编译安装通过但是在实际调用`pytho-ldap`模块过程报错。 最后在Stack Overflow看到[类似问题](http://stackoverflow.com/questions/19311933/redhat-5-4-python-ldap-run-error-python2-7/25199930#25199930)受评论启发，安装python-ldap失败原因是因为`easy_install`自动选择的版本比较新与`CentOS5.8`的`OpenLDAP`不兼容。 解决： 从`python-ldap`的[CVS](http://python-ldap.cvs.sourceforge.net/viewvc/python-ldap/python-ldap/?pathrev=PYLDAP_REL_2_2_1)下载较老的版本，编译安装OK12342. 按照表单填写了ReviewBoard的LDAP认证信息，无法通过认证 从`openlad`的日志信息来看是ReviewBoard使用了一个错误的用户名密码进行第一次绑定（内网LDAP服务器允许匿名绑定），但是实际我使用的就是匿名绑定，后来发现是浏览器自动缓存了我的ReviewBoard管理员用户名密码用在这里了。很坑爹的故障 LDAP认证正常，依旧无法登陆，报错need more than one value to unpack 问题出在老外的习惯上，ReviewBoard的FullName默认LDAP的attr为displayName，我的服务器的确也是这个规则。最后查询源码发现老外默认从fullname中去解析 sn（surname）和cn（commonname），而且还是用一个空格分隔。故障accounts/backends.py源码如下，注意中间的注释。PS：在这里告诉我，这个小的问题LDAP管理员应该能搞定~~还（KENG）好（DIE） 解决：删除fullName的配置或者告诉LDAP管理员在displayName中添加空格 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778def get_or_create_user(self, username): username = username.strip() try: user = User.objects.get(username=username) return user except User.DoesNotExist: try: import ldap ldapo = ldap.initialize(settings.LDAP_URI) ldapo.set_option(ldap.OPT_REFERRALS, 0) ldapo.set_option(ldap.OPT_PROTOCOL_VERSION, 3) if settings.LDAP_TLS: ldapo.start_tls_s() if settings.LDAP_ANON_BIND_UID: ldapo.simple_bind_s(settings.LDAP_ANON_BIND_UID, settings.LDAP_ANON_BIND_PASSWD) passwd = ldapo.search_s(settings.LDAP_BASE_DN, ldap.SCOPE_SUBTREE, settings.LDAP_UID_MASK % username) user_info = passwd[0][1] given_name_attr = getattr(settings, 'LDAP_GIVEN_NAME_ATTRIBUTE', 'givenName') first_name = user_info.get(given_name_attr, [username])[0] surname_attr = getattr(settings, 'LDAP_SURNAME_ATTRIBUTE', 'sn') last_name = user_info.get(surname_attr, [''])[0] # If a single ldap attribute is used to hold the full name of # a user, split it into two parts. Where to split was a coin # toss and I went with a left split for the first name and # dumped the remainder into the last name field. The system # admin can handle the corner cases. try: if settings.LDAP_FULL_NAME_ATTRIBUTE: full_name = user_info[settings.LDAP_FULL_NAME_ATTRIBUTE][0] first_name, last_name = full_name.split(' ', 1) except AttributeError: pass if settings.LDAP_EMAIL_DOMAIN: email = u'%s@%s' % (username, settings.LDAP_EMAIL_DOMAIN) elif settings.LDAP_EMAIL_ATTRIBUTE: email = user_info[settings.LDAP_EMAIL_ATTRIBUTE][0] else: logging.warning(\"LDAP: email for user %s is not specified\", username) email = '' user = User(username=username, password='', first_name=first_name, last_name=last_name, email=email) user.is_staff = False user.is_superuser = False user.set_unusable_password() user.save() return user except ImportError: pass except ldap.INVALID_CREDENTIALS: # FIXME I'd really like to warn the user that their # ANON_BIND_UID and ANON_BIND_PASSWD are wrong, but I don't # know how pass except ldap.NO_SUCH_OBJECT, e: logging.warning(\"LDAP error: %s settings.LDAP_BASE_DN: %s \" \"settings.LDAP_UID_MASK: %s\" % (e, settings.LDAP_BASE_DN, settings.LDAP_UID_MASK % username)) except ldap.LDAPError, e: logging.warning(\"LDAP error: %s\" % e) return None","categories":[{"name":"Tools","slug":"Tools","permalink":"http://blog.beanmr.com/categories/Tools/"}],"tags":[{"name":"ReviewBoard","slug":"ReviewBoard","permalink":"http://blog.beanmr.com/tags/ReviewBoard/"},{"name":"LDAP","slug":"LDAP","permalink":"http://blog.beanmr.com/tags/LDAP/"},{"name":"python-ldap","slug":"python-ldap","permalink":"http://blog.beanmr.com/tags/python-ldap/"}]},{"title":"SVNManager用户和组权限报错","slug":"2013-11-28-svnmanager-troubleshooting","date":"2019-03-20T03:11:09.934Z","updated":"2019-03-20T03:50:14.097Z","comments":true,"path":"2013-11-28-svnmanager-troubleshooting/","link":"","permalink":"http://blog.beanmr.com/2013-11-28-svnmanager-troubleshooting/","excerpt":"","text":"SVNManager是非常受大家欢迎的一个SVN管理工具。这里记录一个关于权限设置的Troubleshooting以备后用。 SVNManager用户和组权限报错今天在帮朋友搭建时用户和组权限设定的功能不能正常工作，出现空白页面，查看后台Apache的日志发现报错如下： 12PHP Fatal error: Class 'PEAR_ErrorStack' not found in /var/www/html/svnmanager/svnmanager/RepositoryModule/UserPrivilegesEditPage.php on line 203 问题出现在VersionControl_SVN版本不兼容问题，主要是默认的PHP版本太老了。12# pear listVersionControl_SVN 0.5.1 alpha需要依赖如下,各个版本的依赖情况可以到这个查看。 123pear/VersionControl_SVN requires PHP (version &gt;= 5.3.0), installed version is 5.1.6pear/VersionControl_SVN requires PEAR Installer (version &gt;= 1.9.4), installed version is 1.4.9pear/VersionControl_SVN requires package \"pear/PEAR\" (version &gt;= 1.9.4), installed version is 1.4.9 替换老的版本，当然也可以升级PHP。 1pear install VersionControl_SVN-0.3.4","categories":[{"name":"Tools","slug":"Tools","permalink":"http://blog.beanmr.com/categories/Tools/"}],"tags":[{"name":"SCM","slug":"SCM","permalink":"http://blog.beanmr.com/tags/SCM/"},{"name":"SVNManager","slug":"SVNManager","permalink":"http://blog.beanmr.com/tags/SVNManager/"},{"name":"Troubleshooting","slug":"Troubleshooting","permalink":"http://blog.beanmr.com/tags/Troubleshooting/"}]},{"title":"WordPress for SAE安装JetPack使用Markdown","slug":"2014-8-1-WordPressForSAE-JetPack-Markdown","date":"2019-03-20T03:11:09.934Z","updated":"2019-03-20T03:50:14.029Z","comments":true,"path":"2014-8-1-WordPressForSAE-JetPack-Markdown/","link":"","permalink":"http://blog.beanmr.com/2014-8-1-WordPressForSAE-JetPack-Markdown/","excerpt":"","text":"记一次WordPress for SAE安装JetPack使用Markdown写博文的经历。 WordPress for SAE安装JetPack使用Markdown至于说为什么选Wordpress而且是WordPress for SAE做个人的博客，答案就一个字“省事”。 PS：现在在GitHub上了“省事” “省钱” “貌似很拽”！ 想用Markdown写东西，网上有WP的Markdown支持方法，他们需要考虑老数据转换的问题，所以看上去挺繁琐的。我的新博虽然没有老数据转换的问题，但也不想那么弄。毕竟每个解析程序生成的HTML都会有大大小小的差异，如果文章固定在WP的Markdown上如果以后转换也是麻烦。 就还用Stackedit写Markdown然后直接用它将转换成HTML往博客里面发布，又省事又不用老开着博客。这个功能其实Stackedit本身就有的，但是在折腾的时候也有点小问题所以就记录在这里。 实现使用Stackedit自身的发布到WP的功能 问题 Stackedit的发布需要WP有Jetpack plugin的支持 当前的Jetpack默认要求Wordpress 3.5以上 WordPress for SAE的WP是3.4.1而且不能升级WP WP被墙着呢 解决解决方案很简单那就是找个能适用于3.4.1的Jetpack就可以了。我尝试了几个版本最后发现2.2版本就可以用，但是发行包估计找不到了在这里给打架贡献一下地址。在Jetpack的SVN的这里签出就搞定了。因为WP被墙着开始配置的时候大家自行解决就好了。","categories":[{"name":"WordPress","slug":"WordPress","permalink":"http://blog.beanmr.com/categories/WordPress/"}],"tags":[{"name":"Troubleshooting","slug":"Troubleshooting","permalink":"http://blog.beanmr.com/tags/Troubleshooting/"},{"name":"SAE","slug":"SAE","permalink":"http://blog.beanmr.com/tags/SAE/"},{"name":"JetPack","slug":"JetPack","permalink":"http://blog.beanmr.com/tags/JetPack/"},{"name":"Markdown","slug":"Markdown","permalink":"http://blog.beanmr.com/tags/Markdown/"}]},{"title":"NodeJS事件驱动-时间轴并发","slug":"2014-8-1-NodeJS-EventDrive","date":"2019-03-20T03:11:09.934Z","updated":"2019-03-20T03:50:14.010Z","comments":true,"path":"2014-8-1-NodeJS-EventDrive/","link":"","permalink":"http://blog.beanmr.com/2014-8-1-NodeJS-EventDrive/","excerpt":"","text":"NodeJS-时间轴的并发NodeJS最大的优势是在高并发下的高吞吐量，这得益于它最大的特色事件驱动和异步，看过一篇文章介绍NodeJS成也在此败也在此。大致整理一下我对它的理解，放在这里以备后用。 先说一下线程并发模型，然后进一步说说NodeJS的时间驱动单进程模型带来的优势。 并发的线程（进程）模型为了解释程序的运行过程假设存在有这么一个业务流程： 程序接受请求，开始从网络拉去数据CPUt1 客户端从网络发送请求数据时间耗时 IOt1 程序分析请求，并发送数据库请求耗时需要CPUt2 程序获取数据库返回数据时间IOt2 程序分析结果，构造返回结果耗时CPUt3 程序向网络发送结果耗时IOt3 这个是典型的数据查询操作，这个业务流程需要的时间位T=IOt[1,2,3]+CPUt[1,2,3],另外在多线程环境下还要考虑一个线程上下文切换时间sc,当然线程内堆栈切换、现场保护也是需要时间的但总台来说进程切换消耗&gt;线程间切换时间&gt;线程内上下文切换时间。 假设硬件是单CPU系统，同理多CPU就是多几套单CPU结构。 单线程程序 接收到一个处理请求程序按照预定的命令序列依次执行。当程序运行到IO等操作时会等待其完成，此时间段不进行其它的工作，此时程序可能放弃CPU，但此时只有一个线程运行，那么CPU是空闲的，这是一个硬件资源的浪费。程序每处理一个请求，当前程序请求完成后继续处理下一个请求。 那么每个业务时间CPUt+IOt，程序整体单位时间的吞吐量就是1/T 多线程程序 当程序接受到一个请求后，会分配给一个线程去执行，然后继续接受下一个请求，分配给新的线程。当线程运行到IO操作时，此线程会放弃CPU，发生一次线程间切换操作，当前操作等待IO换到其它需要需要CPU运算的线程。 不考虑线程切换时间sc，假设让CPU满负载，那么程序应该每当一个线程运行完需要CPU运算的部分就正好切换上另外一个线程,那么CPU的吞吐量1/CPUt，也就是说系统的吞吐量收CPUt影响最大。此时需要的并发线程数就是CPUt，假设的CPUt=2ms，那么程序的理论每秒吞吐量为500req，线程并发数是500。但是如果单核真的开启500个线程，那么系统的会花大量的时间去维护线程间切换，那么sc时间会大大增加，系统的吞吐量将远远小于500。 在多线程环境下其实的业务流程时间应该为CPUt+IOt+5sc,也就是每次请求要多5个sc的时间，所以处理500req需求的时间就不再是1s。而且随着并发线程数的增多么次sc的时间是增加的。其实线程数的最佳数值基本是固定的范围内波动的，估算应该是略低于内核数/业务平均CPUt。虽然可以通过优化算法缩短CPUt，但随着CPUt的优化，就需要更多的并发线程，那么sc耗时就不能忽略，可能优化的CPUt获得的优势反倒会被sc时间抵消。也就是说缩短CPUt优化会受到上下文切换的瓶颈，再说如果计算本身很简单也没什么优化空间。 当前我的系统就是一个并发数比较高、每次CPUt比较小（数据处理很简单）的系统，在高并发的情况下，通过再增加Tomcat的线程数也起不到很好的效果。 NodeJS的单进程事件驱动模型在上文介绍了单线程模式，提到了单线程（进程）存在资源浪费导致系统的吞吐量变低。而NodeJS程序虽然也是单进程模式，反倒有了更大的吞吐量这就得益于他的事件驱动模型。 在进程中事件派发线程负责收集事件，当有请求到达时程序时程序就执行业务的1号操作，1号操作执行完成了，NodeJS并不是想单线程一样傻等，而是接着去看看有没有新的事件发生，在高并发的情况下新请求在排队，那么很快NodeJS程序就会继续处理1号操作；当第一个请求的IO发生完成的时候，它也会触发一个事件这个事件也去排队，程序处理完了手头的东西一低头看见原来第一个请求的IO操作完成了，那我就为他做3号操作。之所以NodeJS程序知道2号IO操作执行完成了应该做第三号操作，是因为在为他安排2号工作时就告诉了它说“当2号操作完成后做….”，这指示我们通过回调函数完成。比如下面一个Mongodb的操作流程被划为成了，打开数据库回调-&gt;打开Collection回调-&gt;执行数据操作回调。这样NodeJS是靠某件事情发生了去做什么安排程序运行的，而不是像原来一样程序一口气跑到黑，这就是事件驱动了。这样做有个好处就是我们的程序的一个线程不再是做一个请求，而是能同时处理处理多个请求。这样达到了多线程的效果而且没有线程间切换（至少很少）。 如上所述因为线程一直在忙，只要有事就在做而且不等待IO不切换线程，所以宏观上看到的请求处理时间为CPUt+IOt，但是CPU看到的是一直有CPUt需要处理因为等待IOt的时间有下一个CPUt需要处理。因为没有线程间切换所有也就没有了sc的时间，所以我们此时的吞吐瓶颈将是1/CPUt。也正是因此NodeJS不适合于CPU运算密集性的系统，它更适合CPUt很小，IOt很大的系统。","categories":[{"name":"NodeJS","slug":"NodeJS","permalink":"http://blog.beanmr.com/categories/NodeJS/"}],"tags":[{"name":"NodeJS","slug":"NodeJS","permalink":"http://blog.beanmr.com/tags/NodeJS/"},{"name":"事件驱动","slug":"事件驱动","permalink":"http://blog.beanmr.com/tags/事件驱动/"},{"name":"并发","slug":"并发","permalink":"http://blog.beanmr.com/tags/并发/"}]}]}